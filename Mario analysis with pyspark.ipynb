{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F, types as T\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# https://github.com/kevinschaich/pyspark-cheatsheet\n",
    "# https://github.com/edyoda/pyspark-tutorial/blob/master/PySpark-DataFrames.ipynb\n",
    "# https://towardsdatascience.com/7-must-know-pyspark-functions-d514ca9376b9\n",
    "# https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.html    lista med alla metoder\n",
    "# https://sparkbyexamples.com/pyspark/pyspark-aggregate-functions/\n",
    "# https://www.geeksforgeeks.org/multiple-criteria-for-aggregation-on-pyspark-dataframe/\n",
    "# https://sparkbyexamples.com/pyspark/pyspark-column-functions/  #visar funktionerna \n",
    "# https://stackoverflow.com/questions/52264844/how-get-the-percentage-of-totals-for-each-count-after-a-groupby-in-pyspark  visar withColumn och procent\n",
    "\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName('SparkApp').setMaster('local')\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "spark = SparkSession(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----------+\n",
      "|               catch|                 id|     player|\n",
      "+--------------------+-------------------+-----------+\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|  darter60k|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|davidchofis|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35| fabioviana|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|  gorigokky|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|groebenzell|\n",
      "+--------------------+-------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the csv plays have tabs as deliminator  \"\\t\"\n",
    "df_play = spark.read.options(header='True', inferSchema='True', delimiter=  \"\\t\").csv(\"plays.csv\")\n",
    "df_play.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the players that have played the most nbr of times, using 2 ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+\n",
      "|          player|Frequency|\n",
      "+----------------+---------+\n",
      "| Conducteur59220|     2681|\n",
      "|        dellbox2|     1951|\n",
      "|         AE4WiiU|     1686|\n",
      "|        revolv23|     1437|\n",
      "|demonhunter47223|     1246|\n",
      "|    WIIMoustique|     1244|\n",
      "|buddy1943indiana|     1242|\n",
      "| Plusbellelavie5|     1234|\n",
      "|   Feuxdelamoule|     1096|\n",
      "|      cowboye123|     1068|\n",
      "|   quentintheret|     1035|\n",
      "|        Tylano64|     1010|\n",
      "|       jacky1303|      989|\n",
      "|         apoc_ze|      958|\n",
      "|RURI333HRIRU777H|      944|\n",
      "+----------------+---------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the players\n",
    "df_play.groupBy('player').agg(F.count('*').alias('Frequency')).orderBy('Frequency', ascending=False).show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "|          player|count(player)|\n",
      "+----------------+-------------+\n",
      "| Conducteur59220|         2681|\n",
      "|        dellbox2|         1951|\n",
      "|         AE4WiiU|         1686|\n",
      "|        revolv23|         1437|\n",
      "|demonhunter47223|         1246|\n",
      "|    WIIMoustique|         1244|\n",
      "|buddy1943indiana|         1242|\n",
      "| Plusbellelavie5|         1234|\n",
      "|   Feuxdelamoule|         1096|\n",
      "|      cowboye123|         1068|\n",
      "|   quentintheret|         1035|\n",
      "|        Tylano64|         1010|\n",
      "|       jacky1303|          989|\n",
      "|         apoc_ze|          958|\n",
      "|RURI333HRIRU777H|          944|\n",
      "|      Alexis2012|          919|\n",
      "|       shinbu-10|          894|\n",
      "|      shailo1996|          870|\n",
      "|        Leeshino|          831|\n",
      "|        666666io|          822|\n",
      "+----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Another way to use agg, but now I can't use alias to rename the column in a good way \n",
    "df_play.groupBy('player').agg({'player':'count'}).orderBy('count(player)', ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new date column and view most popular days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the most popular days and hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------+----------+----------+\n",
      "|               catch|                 id|        player|      date|year_month|\n",
      "+--------------------+-------------------+--------------+----------+----------+\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|     darter60k|2018-02-23|   2018-02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|   davidchofis|2018-02-23|   2018-02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|    fabioviana|2018-02-23|   2018-02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|     gorigokky|2018-02-23|   2018-02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|   groebenzell|2018-02-23|   2018-02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|        heikez|2018-02-23|   2018-02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|   igatake0229|2018-02-23|   2018-02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|     martiwish|2018-02-23|   2018-02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|      risa.lll|2018-02-23|   2018-02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35| SkooterBicuit|2018-02-23|   2018-02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|     swimmer72|2018-02-23|   2018-02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|Thank_you.0039|2018-02-23|   2018-02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|     ukgirl617|2018-02-23|   2018-02|\n",
      "|2018-03-02 09:46:...|0000-0000-035A-9F14|       apabaez|2018-03-02|   2018-03|\n",
      "|2018-03-02 09:46:...|0000-0000-035A-9F14|      eitogogo|2018-03-02|   2018-03|\n",
      "|2018-03-02 09:46:...|0000-0000-035A-9F14|    eliatas112|2018-03-02|   2018-03|\n",
      "|2018-03-02 09:46:...|0000-0000-035A-9F14|   eric321luis|2018-03-02|   2018-03|\n",
      "|2018-03-02 09:46:...|0000-0000-035A-9F14|        haon.m|2018-03-02|   2018-03|\n",
      "|2018-03-02 09:46:...|0000-0000-035A-9F14|   holstein_17|2018-03-02|   2018-03|\n",
      "|2018-03-02 09:46:...|0000-0000-035A-9F14|        jlan6e|2018-03-02|   2018-03|\n",
      "+--------------------+-------------------+--------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create new columns: Extract the 10 first characters from catch and name it date\n",
    "# use withColumn method\n",
    "df_play = df_play.withColumn('date', df_play.catch.substr(0,10))  #make to it is only the date is in one column\n",
    "df_play = df_play.withColumn('year_month', df_play.catch.substr(0,7))  #make to it is only the year and month are one column\n",
    "df_play.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|      date|count(date)|\n",
      "+----------+-----------+\n",
      "|2017-11-16|      82532|\n",
      "|2017-11-17|       1862|\n",
      "|2017-11-18|       1447|\n",
      "|2017-11-19|       1404|\n",
      "|2017-11-20|       1881|\n",
      "|2017-11-21|        516|\n",
      "|2017-11-22|        342|\n",
      "|2017-11-23|        437|\n",
      "|2017-11-24|         48|\n",
      "|2017-12-15|       5948|\n",
      "|2017-12-16|        472|\n",
      "|2017-12-17|        370|\n",
      "|2017-12-18|     976096|\n",
      "|2017-12-19|       8895|\n",
      "|2017-12-20|       3016|\n",
      "|2017-12-21|        416|\n",
      "|2018-01-02|      43815|\n",
      "|2018-01-03|       3413|\n",
      "|2018-01-04|       3477|\n",
      "|2018-01-05|       3402|\n",
      "+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nbr of plays for each day\n",
    "df_date = df_play.groupBy('date').agg({'date': 'count'}).orderBy('date')\n",
    "df_date.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|hour|count(hour)|\n",
      "+----+-----------+\n",
      "|  00|       6490|\n",
      "|  01|       5535|\n",
      "|  02|       5270|\n",
      "|  03|       4945|\n",
      "|  04|       5173|\n",
      "|  05|       5359|\n",
      "|  06|       6267|\n",
      "|  07|      29637|\n",
      "|  08|      25488|\n",
      "|  09|     366047|\n",
      "|  10|     898340|\n",
      "|  11|      29931|\n",
      "|  12|       7800|\n",
      "|  13|       8961|\n",
      "|  14|     747774|\n",
      "|  15|    1386810|\n",
      "|  16|     331074|\n",
      "|  17|      20004|\n",
      "|  18|      11296|\n",
      "|  19|       7578|\n",
      "+----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The most common hour when a user is playing\n",
    "# substr(startPosition, lenght)\n",
    "df_play = df_play.withColumn('hour', df_play.catch.substr(12, 2))\n",
    "df_play = df_play.withColumn('month', df_play.catch.substr(6, 2))\n",
    "\n",
    "df_hour = df_play.groupBy('hour').agg({'hour': 'count'}).orderBy('hour')\n",
    "df_hour.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------+----------+----------+----+-----+\n",
      "|               catch|                 id|        player|      date|year_month|hour|month|\n",
      "+--------------------+-------------------+--------------+----------+----------+----+-----+\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|     darter60k|2018-02-23|   2018-02|  15|   02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|   davidchofis|2018-02-23|   2018-02|  15|   02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|    fabioviana|2018-02-23|   2018-02|  15|   02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|     gorigokky|2018-02-23|   2018-02|  15|   02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|   groebenzell|2018-02-23|   2018-02|  15|   02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|        heikez|2018-02-23|   2018-02|  15|   02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|   igatake0229|2018-02-23|   2018-02|  15|   02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|     martiwish|2018-02-23|   2018-02|  15|   02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|      risa.lll|2018-02-23|   2018-02|  15|   02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35| SkooterBicuit|2018-02-23|   2018-02|  15|   02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|     swimmer72|2018-02-23|   2018-02|  15|   02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|Thank_you.0039|2018-02-23|   2018-02|  15|   02|\n",
      "|2018-02-23 15:22:...|0000-0000-0353-3D35|     ukgirl617|2018-02-23|   2018-02|  15|   02|\n",
      "|2018-03-02 09:46:...|0000-0000-035A-9F14|       apabaez|2018-03-02|   2018-03|  09|   03|\n",
      "|2018-03-02 09:46:...|0000-0000-035A-9F14|      eitogogo|2018-03-02|   2018-03|  09|   03|\n",
      "|2018-03-02 09:46:...|0000-0000-035A-9F14|    eliatas112|2018-03-02|   2018-03|  09|   03|\n",
      "|2018-03-02 09:46:...|0000-0000-035A-9F14|   eric321luis|2018-03-02|   2018-03|  09|   03|\n",
      "|2018-03-02 09:46:...|0000-0000-035A-9F14|        haon.m|2018-03-02|   2018-03|  09|   03|\n",
      "|2018-03-02 09:46:...|0000-0000-035A-9F14|   holstein_17|2018-03-02|   2018-03|  09|   03|\n",
      "|2018-03-02 09:46:...|0000-0000-035A-9F14|        jlan6e|2018-03-02|   2018-03|  09|   03|\n",
      "+--------------------+-------------------+--------------+----------+----------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now a lot more of columns regarding date and time have been added\n",
    "df_play.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many times a player played for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+---------+\n",
      "|          player|      date|Frequency|\n",
      "+----------------+----------+---------+\n",
      "| Conducteur59220|2018-02-23|     1864|\n",
      "|    WIIMoustique|2018-02-23|     1069|\n",
      "| Plusbellelavie5|2018-02-23|      918|\n",
      "|      cowboye123|2018-02-23|      835|\n",
      "|   Feuxdelamoule|2018-02-23|      791|\n",
      "|   quentintheret|2018-02-23|      790|\n",
      "|        Tylano64|2018-02-23|      757|\n",
      "|        dellbox2|2018-02-23|      738|\n",
      "|        dellbox2|2017-12-18|      677|\n",
      "|      indien1966|2018-02-23|      605|\n",
      "|          sioux4|2018-02-23|      593|\n",
      "|        Leeshino|2018-02-23|      584|\n",
      "|        revolv23|2018-02-23|      583|\n",
      "|         AE4WiiU|2018-02-23|      576|\n",
      "|buddy1943indiana|2018-02-23|      556|\n",
      "+----------------+----------+---------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_play.groupBy('player', 'date').agg(F.count('*').alias('Frequency')).orderBy('Frequency', ascending=False).show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First day a player playes a level for a month, with 2 methods\n",
    "\n",
    "Lets see when a player first playes a level for the given month \n",
    "\n",
    "First method uses window.partitionBy where I rank each observation and select the first one\n",
    "\n",
    "The second method is more simple and just uses the method .distinct() that keepes the first observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------------+----------+----------+----+-----+-------+\n",
      "|               catch|                 id|         player|      date|year_month|hour|month|row_nbr|\n",
      "+--------------------+-------------------+---------------+----------+----------+----+-----+-------+\n",
      "|2017-11-16 14:45:...|085F-0000-0364-6DA1|Conducteur59220|2017-11-16|   2017-11|  14|   11|      1|\n",
      "|2017-12-18 14:48:...|000E-0000-0331-2D8D|Conducteur59220|2017-12-18|   2017-12|  14|   12|      1|\n",
      "|2018-01-03 11:35:...|4935-0000-0376-984D|Conducteur59220|2018-01-03|   2018-01|  11|   01|      1|\n",
      "|2018-02-01 05:44:...|26EE-0000-0301-E2A0|Conducteur59220|2018-02-01|   2018-02|  05|   02|      1|\n",
      "|2018-03-01 08:56:...|0019-0000-0369-496E|Conducteur59220|2018-03-01|   2018-03|  08|   03|      1|\n",
      "|2018-04-10 11:02:...|2860-0000-0396-CD33|Conducteur59220|2018-04-10|   2018-04|  11|   04|      1|\n",
      "+--------------------+-------------------+---------------+----------+----------+----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get number of unique players for each month and the first day they played\n",
    "# https://stackoverflow.com/questions/60779612/pyspark-get-the-last-observation-in-each-subgroup\n",
    "# w = Window.partitionBy('year_month', 'player').orderBy(F.desc('year_month'))  # use F.desc to desc orde\n",
    "w = Window.partitionBy('year_month', 'player').orderBy('catch')\n",
    "\n",
    "\n",
    "#adding rownumber to the data\n",
    "\n",
    "# this dataframe is the first for each month\n",
    "df_first_play = df_play.withColumn(\"row_nbr\",F.row_number().over(w))\n",
    "df_first_play = df_first_play.where(F.col('row_nbr') == 1)\n",
    "df_first_play.where(df_play.player == 'Conducteur59220').orderBy('catch', ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+\n",
      "|         player|year_month|\n",
      "+---------------+----------+\n",
      "|Conducteur59220|   2017-11|\n",
      "|Conducteur59220|   2018-01|\n",
      "|Conducteur59220|   2017-12|\n",
      "|Conducteur59220|   2018-03|\n",
      "|Conducteur59220|   2018-02|\n",
      "|Conducteur59220|   2018-04|\n",
      "+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare the method distinct method\n",
    "# One problem with distinct method is that it looks at all columns, so to get the first month I only can select player and month\n",
    "df_play.select('player', 'year_month').orderBy('year_month', ascending=False).distinct().where(df_play.player == 'Conducteur59220').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------------+----------+----------+----+-----+\n",
      "|               catch|                 id|         player|      date|year_month|hour|month|\n",
      "+--------------------+-------------------+---------------+----------+----------+----+-----+\n",
      "|2017-12-18 14:48:...|000E-0000-0331-2D8D|Conducteur59220|2017-12-18|   2017-12|  14|   12|\n",
      "|2018-02-01 05:44:...|26EE-0000-0301-E2A0|Conducteur59220|2018-02-01|   2018-02|  05|   02|\n",
      "|2018-03-01 08:56:...|0019-0000-0369-496E|Conducteur59220|2018-03-01|   2018-03|  08|   03|\n",
      "|2018-04-10 11:02:...|2860-0000-0396-CD33|Conducteur59220|2018-04-10|   2018-04|  11|   04|\n",
      "|2017-11-16 14:45:...|085F-0000-0364-6DA1|Conducteur59220|2017-11-16|   2017-11|  14|   11|\n",
      "|2018-01-03 11:35:...|4935-0000-0376-984D|Conducteur59220|2018-01-03|   2018-01|  11|   01|\n",
      "+--------------------+-------------------+---------------+----------+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Another way is to use dropDuplicates\n",
    "df_play.orderBy('catch', ascending=True).dropDuplicates((['year_month', 'player'])).where(df_play.player == 'Conducteur59220').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------+\n",
      "|first_month|   player_month|row_nbr|\n",
      "+-----------+---------------+-------+\n",
      "|    2017-12|      0-0-0E.MN|      1|\n",
      "|    2017-12|         0-0122|      1|\n",
      "|    2017-12|         0-0550|      1|\n",
      "|    2018-02|        0-0jero|      1|\n",
      "|    2017-12|    0-2-0-6kira|      1|\n",
      "|    2018-02|        0-2-2-8|      1|\n",
      "|    2017-12|      0-5-2-8-A|      1|\n",
      "|    2018-02|         0-6861|      1|\n",
      "|    2018-03|0-9-0-8NABEKINN|      1|\n",
      "|    2017-12|      0-BAEZA-0|      1|\n",
      "|    2018-02|         0-COOL|      1|\n",
      "|    2017-12|       0-Cypher|      1|\n",
      "|    2017-12|      0-ETHAN-0|      1|\n",
      "|    2017-12|       0-HazQ-0|      1|\n",
      "|    2018-03|0-Hydra_Nexus-0|      1|\n",
      "|    2018-03| 0-King-Drake-0|      1|\n",
      "|    2018-03|        0-Robot|      1|\n",
      "|    2018-03|         0-TK-0|      1|\n",
      "|    2018-03|   0-Talisker-0|      1|\n",
      "|    2017-12|    0-Trakeur-0|      1|\n",
      "+-----------+---------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the number of distinct players for each month\n",
    "\n",
    "w = Window.partitionBy('player').orderBy('year_month')\n",
    "\n",
    "\n",
    "# this dataframe is the first month only\n",
    "df_first_month_play = df_play.select('year_month', 'player').withColumn(\"row_nbr\",F.row_number().over(w)).withColumnRenamed('year_month', 'first_month').withColumnRenamed('player', 'player_month')\n",
    "df_first_month_play = df_first_month_play.where(F.col('row_nbr') == 1)\n",
    "df_first_month_play.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the cumulative sum for each day, month and hour\n",
    "\n",
    "There are different ways to calculate the cumulative sum but they all use the function Window to partition over\n",
    "\n",
    "https://www.datasciencemadesimple.com/cumulative-sum-of-column-and-group-in-pyspark/\n",
    "\n",
    "https://stackoverflow.com/questions/54134047/pyspark-get-cumulative-sum-of-of-a-column-with-condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-------+\n",
      "|hour|count(hour)|cum_sum|\n",
      "+----+-----------+-------+\n",
      "|  00|       6490|   6490|\n",
      "|  01|       5535|  12025|\n",
      "|  02|       5270|  17295|\n",
      "|  03|       4945|  22240|\n",
      "|  04|       5173|  27413|\n",
      "|  05|       5359|  32772|\n",
      "|  06|       6267|  39039|\n",
      "|  07|      29637|  68676|\n",
      "|  08|      25488|  94164|\n",
      "|  09|     366047| 460211|\n",
      "|  10|     898340|1358551|\n",
      "|  11|      29931|1388482|\n",
      "|  12|       7800|1396282|\n",
      "|  13|       8961|1405243|\n",
      "|  14|     747774|2153017|\n",
      "|  15|    1386810|3539827|\n",
      "|  16|     331074|3870901|\n",
      "|  17|      20004|3890905|\n",
      "|  18|      11296|3902201|\n",
      "|  19|       7578|3909779|\n",
      "|  20|       8316|3918095|\n",
      "|  21|       8035|3926130|\n",
      "|  22|       8022|3934152|\n",
      "|  23|       7226|3941378|\n",
      "+----+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# One way is to create everything in the same code chunk\n",
    "\n",
    "# notice that the partitionBy is empty, this is because there is no group I want to focus on\n",
    "cum_sum = df_hour.withColumn('cum_sum', F.sum('count(hour)').over(Window.partitionBy().orderBy().rowsBetween(Window.unboundedPreceding, 0)))\n",
    "cum_sum.show(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------+\n",
      "|      date|count(date)|cum_sum|\n",
      "+----------+-----------+-------+\n",
      "|2017-11-16|      82532|  82532|\n",
      "|2017-11-17|       1862|  84394|\n",
      "|2017-11-18|       1447|  85841|\n",
      "|2017-11-19|       1404|  87245|\n",
      "|2017-11-20|       1881|  89126|\n",
      "|2017-11-21|        516|  89642|\n",
      "|2017-11-22|        342|  89984|\n",
      "|2017-11-23|        437|  90421|\n",
      "|2017-11-24|         48|  90469|\n",
      "|2017-12-15|       5948|  96417|\n",
      "|2017-12-16|        472|  96889|\n",
      "|2017-12-17|        370|  97259|\n",
      "|2017-12-18|     976096|1073355|\n",
      "|2017-12-19|       8895|1082250|\n",
      "|2017-12-20|       3016|1085266|\n",
      "|2017-12-21|        416|1085682|\n",
      "|2018-01-02|      43815|1129497|\n",
      "|2018-01-03|       3413|1132910|\n",
      "|2018-01-04|       3477|1136387|\n",
      "|2018-01-05|       3402|1139789|\n",
      "+----------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Another way is to first create a variable for the window function making the query code more easily to read\n",
    "windowval = (Window.partitionBy().orderBy('date').rowsBetween(Window.unboundedPreceding, 0))\n",
    "\n",
    "df_w_cumsum = df_date.withColumn('cum_sum', F.sum('count(date)').over(windowval))\n",
    "\n",
    "df_w_cumsum.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+-------+\n",
      "|      date|year_month|sum(row_nbr)|cum_sum|\n",
      "+----------+----------+------------+-------+\n",
      "|2018-03-01|   2018-03|       10810|  10810|\n",
      "|2018-03-02|   2018-03|      471859| 482669|\n",
      "|2018-03-03|   2018-03|        2606| 485275|\n",
      "|2018-03-04|   2018-03|        2222| 487497|\n",
      "|2018-03-05|   2018-03|        1276| 488773|\n",
      "|2018-03-06|   2018-03|         965| 489738|\n",
      "|2018-03-07|   2018-03|        1030| 490768|\n",
      "|2018-03-08|   2018-03|         891| 491659|\n",
      "|2018-03-09|   2018-03|        1239| 492898|\n",
      "|2018-03-10|   2018-03|        1788| 494686|\n",
      "|2018-03-11|   2018-03|        1558| 496244|\n",
      "|2018-03-12|   2018-03|         726| 496970|\n",
      "|2018-03-13|   2018-03|         726| 497696|\n",
      "|2018-03-14|   2018-03|          32| 497728|\n",
      "+----------+----------+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this show us how many unique players for the month that logged in for the first time that month, lets add a cumulative sum for each month\n",
    "df_first_play_sum = df_first_play.groupBy('date', 'year_month').sum('row_nbr').orderBy('date')\n",
    "\n",
    "# The cumulative sum for each day and month\n",
    "# Notice that I now have a column in partitionBy, this is because there is more than 1 other column\n",
    "windowval = (Window.partitionBy('year_month').orderBy('date').rowsBetween(Window.unboundedPreceding, 0))\n",
    "\n",
    "df_first_play_sum.withColumn('cum_sum', F.sum('sum(row_nbr)').over(windowval)).where(F.col('year_month') == '2018-03').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retention of players\n",
    "\n",
    "Lets see how many players that played for one month and the drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017-11', '2017-12', '2018-01', '2018-03', '2018-02', '2018-04']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list with the start day months for players\n",
    "# This will not be used but is good to know\n",
    "start_day_list = df_first_play.select('year_month').rdd.map(lambda row : row[0]).distinct().collect()\n",
    "start_day_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------+\n",
      "|first_month|   player_month|row_nbr|\n",
      "+-----------+---------------+-------+\n",
      "|    2017-12|      0-0-0E.MN|      1|\n",
      "|    2017-12|         0-0122|      1|\n",
      "|    2017-12|         0-0550|      1|\n",
      "|    2018-02|        0-0jero|      1|\n",
      "|    2017-12|    0-2-0-6kira|      1|\n",
      "|    2018-02|        0-2-2-8|      1|\n",
      "|    2017-12|      0-5-2-8-A|      1|\n",
      "|    2018-02|         0-6861|      1|\n",
      "|    2018-03|0-9-0-8NABEKINN|      1|\n",
      "|    2017-12|      0-BAEZA-0|      1|\n",
      "|    2018-02|         0-COOL|      1|\n",
      "|    2017-12|       0-Cypher|      1|\n",
      "|    2017-12|      0-ETHAN-0|      1|\n",
      "|    2017-12|       0-HazQ-0|      1|\n",
      "|    2018-03|0-Hydra_Nexus-0|      1|\n",
      "|    2018-03| 0-King-Drake-0|      1|\n",
      "|    2018-03|        0-Robot|      1|\n",
      "|    2018-03|         0-TK-0|      1|\n",
      "|    2018-03|   0-Talisker-0|      1|\n",
      "|    2017-12|    0-Trakeur-0|      1|\n",
      "+-----------+---------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This code was used before, it is used to select the first month a player played\n",
    "# this will be used as the players first month when calculating the retention rate\n",
    "w = Window.partitionBy('player').orderBy('year_month')\n",
    "\n",
    "\n",
    "# this dataframe is the first month only\n",
    "df_first_month_play = df_play.select('year_month', 'player').withColumn(\"row_nbr\",F.row_number().over(w)).withColumnRenamed('year_month', 'first_month').withColumnRenamed('player', 'player_month')\n",
    "df_first_month_play = df_first_month_play.where(F.col('row_nbr') == 1)\n",
    "df_first_month_play.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+\n",
      "|          player|year_month|\n",
      "+----------------+----------+\n",
      "|    ProfAmaretto|   2018-03|\n",
      "|       recre8ion|   2018-02|\n",
      "|      LouisWu182|   2018-02|\n",
      "|     spunkybabes|   2017-12|\n",
      "|         Stoli23|   2018-03|\n",
      "|   snorlax082008|   2018-03|\n",
      "|         lolalao|   2018-03|\n",
      "|       andrelloo|   2018-03|\n",
      "|       kougi1974|   2018-04|\n",
      "|     Boneshark71|   2017-12|\n",
      "|BernardoVDourado|   2017-12|\n",
      "|         aas2011|   2018-03|\n",
      "|    kazkaz160602|   2018-03|\n",
      "|         Alew110|   2018-02|\n",
      "|     lalomendoza|   2017-12|\n",
      "|       opperkoek|   2018-02|\n",
      "|       joelmaria|   2018-03|\n",
      "|      sateraaito|   2018-02|\n",
      "|      hiroki1682|   2018-03|\n",
      "|         MAEKEN1|   2018-02|\n",
      "+----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To calculate retention I will select the first month a player played as start and then see how many of those players are still active every month\n",
    "df_player_activity = df_play.select('player', 'year_month').distinct()\n",
    "df_player_activity.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+-----------+\n",
      "|         player|year_month|first_month|\n",
      "+---------------+----------+-----------+\n",
      "|      0-0-0E.MN|   2017-12|    2017-12|\n",
      "|      0-0-0E.MN|   2018-02|    2017-12|\n",
      "|         0-0122|   2017-12|    2017-12|\n",
      "|         0-0122|   2018-03|    2017-12|\n",
      "|         0-0550|   2017-12|    2017-12|\n",
      "|         0-0916|   2018-02|    2018-02|\n",
      "|        0-0jero|   2018-02|    2018-02|\n",
      "|    0-2-0-6kira|   2017-12|    2017-12|\n",
      "|        0-2-2-8|   2018-02|    2018-02|\n",
      "|      0-5-2-8-A|   2017-12|    2017-12|\n",
      "|      0-5-2-8-A|   2018-03|    2017-12|\n",
      "|      0-5-2-8-A|   2018-02|    2017-12|\n",
      "|         0-6861|   2018-02|    2018-02|\n",
      "|0-9-0-8NABEKINN|   2018-03|    2018-03|\n",
      "|      0-BAEZA-0|   2017-12|    2017-12|\n",
      "|         0-COOL|   2018-03|    2018-02|\n",
      "|         0-COOL|   2018-02|    2018-02|\n",
      "|       0-Cypher|   2017-12|    2017-12|\n",
      "|      0-ETHAN-0|   2018-03|    2017-12|\n",
      "|      0-ETHAN-0|   2018-02|    2017-12|\n",
      "+---------------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine the df with all the players distinct activites for all months and add a column that shows which month that is the first \n",
    "\n",
    "df_retention = df_player_activity.join(df_first_month_play , df_player_activity.player == df_first_month_play.player_month, 'left').select('player', 'year_month', 'first_month')\n",
    "df_retention.orderBy('player').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+-----------+\n",
      "|         player|year_month|first_month|\n",
      "+---------------+----------+-----------+\n",
      "|Conducteur59220|   2017-11|    2017-11|\n",
      "|Conducteur59220|   2018-01|    2017-11|\n",
      "|Conducteur59220|   2017-12|    2017-11|\n",
      "|Conducteur59220|   2018-03|    2017-11|\n",
      "|Conducteur59220|   2018-02|    2017-11|\n",
      "|Conducteur59220|   2018-04|    2017-11|\n",
      "+---------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets take a look at the famous player Conducteur59220 and control that it looks correct \n",
    "# Now there is one column (year_month) that shows every month that Conducteur59220 have been playing\n",
    "# And one column (first_month) that shows the first month only, now it will be easy to calculate the retention rate\n",
    "df_retention.where(F.col('player') == 'Conducteur59220').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+-----------+--------------------+-------+---------+\n",
      "|first_month|year_month|nbr_players|max_players|      retantion_rate|row_num|nbr_month|\n",
      "+-----------+----------+-----------+-----------+--------------------+-------+---------+\n",
      "|    2017-11|   2017-11|      66199|      66199|                 1.0|      1|  month_1|\n",
      "|    2017-11|   2017-12|      47139|      66199|  0.7120802429039713|      2|  month_2|\n",
      "|    2017-11|   2018-01|       8445|      66199| 0.12756990286862338|      3|  month_3|\n",
      "|    2017-11|   2018-02|      49131|      66199|   0.742171331893231|      4|  month_4|\n",
      "|    2017-11|   2018-03|      48842|      66199|  0.7378057070348495|      5|  month_5|\n",
      "|    2017-11|   2018-04|       1114|      66199| 0.01682804876206589|      6|  month_6|\n",
      "|    2017-12|   2017-12|     358117|     358117|                 1.0|      1|  month_1|\n",
      "|    2017-12|   2018-01|      23051|     358117| 0.06436723193816546|      2|  month_2|\n",
      "|    2017-12|   2018-02|     196934|     358117|  0.5499152511609334|      3|  month_3|\n",
      "|    2017-12|   2018-03|     193895|     358117|  0.5414291977202981|      4|  month_4|\n",
      "|    2017-12|   2018-04|       1777|     358117|0.004962065470223418|      5|  month_5|\n",
      "|    2018-01|   2018-01|      39424|      39424|                 1.0|      1|  month_1|\n",
      "|    2018-01|   2018-02|      21470|      39424|  0.5445921266233766|      2|  month_2|\n",
      "|    2018-01|   2018-03|      21274|      39424|  0.5396205357142857|      3|  month_3|\n",
      "|    2018-01|   2018-04|        527|      39424|0.013367491883116884|      4|  month_4|\n",
      "|    2018-02|   2018-02|     238307|     238307|                 1.0|      1|  month_1|\n",
      "|    2018-02|   2018-03|      85534|     238307|  0.3589235733738413|      2|  month_2|\n",
      "|    2018-02|   2018-04|        885|     238307|0.003713697037854532|      3|  month_3|\n",
      "|    2018-03|   2018-03|     148183|     148183|                 1.0|      1|  month_1|\n",
      "|    2018-03|   2018-04|        575|     148183|0.003880337150685...|      2|  month_2|\n",
      "+-----------+----------+-----------+-----------+--------------------+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code to create the retention data, all that is left is to pivot the table so nbr of months are the columns and first month is just one row\n",
    "# The code counts how many times players that occurs for the first month and then create a column with the max value\n",
    "# I then created a new column with the max value of players, since the first month will always have the max value or be equal \n",
    "# The retention rate is then calculated as the nbr of players for a given month / max players (players in the first month cohort)\n",
    "\n",
    "df_retention = df_retention.groupBy('first_month', 'year_month' ).agg(F.count('player').alias('nbr_players'))\\\n",
    "  .withColumn(\"max_players\",  F.max(\"nbr_players\").over(Window.partitionBy('first_month'))).orderBy('first_month', 'year_month') \\\n",
    "  .withColumn(\"retantion_rate\", F.col(\"nbr_players\") / F.max(\"nbr_players\").over(Window.partitionBy('first_month'))).orderBy('first_month', 'year_month')\\\n",
    "  .withColumn('row_num', F.row_number().over(Window.partitionBy('first_month').orderBy('year_month')))\\\n",
    "  .withColumn(\"nbr_month\", F.concat(F.lit(\"month_\"), F.col(\"row_num\")))\n",
    "\n",
    "df_retention.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "|first_month|month_1|             month_2|             month_3|             month_4|             month_5|            month_6|\n",
      "+-----------+-------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "|    2017-11|    1.0|  0.7120802429039713| 0.12756990286862338|   0.742171331893231|  0.7378057070348495|0.01682804876206589|\n",
      "|    2017-12|    1.0| 0.06436723193816546|  0.5499152511609334|  0.5414291977202981|0.004962065470223418|               null|\n",
      "|    2018-01|    1.0|  0.5445921266233766|  0.5396205357142857|0.013367491883116884|                null|               null|\n",
      "|    2018-02|    1.0|  0.3589235733738413|0.003713697037854532|                null|                null|               null|\n",
      "|    2018-03|    1.0|0.003880337150685...|                null|                null|                null|               null|\n",
      "|    2018-04|    1.0|                null|                null|                null|                null|               null|\n",
      "+-----------+-------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the table above to pivot it to nbr_month as columns\n",
    "# This table shows the retentation rate given the first month as cohort \n",
    "df_retention.groupBy('first_month').pivot('nbr_month').sum('retantion_rate').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('Spacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "313f8f3735f8315f9885436dad6dc9fda36d9ed7e686614f418822e8edb67855"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
